---
title: "..."
---


```{r eval = TRUE,  message=F, include=FALSE, warning=F, purl=F, results="hide"}
knitr::purl('maps.Rmd', documentation = 0)
```


```{r echo=FALSE, purl=F}
xfun::embed_file('maps.Rmd')
```

```{r echo=FALSE, purl=F}
xfun::embed_file('maps.R')
```


```{r echo=FALSE}
xaringanExtra::use_clipboard()
```

-----------------------

This is an introduction to spatial data manipulation with R and the terra package. In this context “spatial data” refers to data about geographical locations, that is, places on earth. So to be more precise, we should speak about **geospatial** data, but we use the shorthand **spatial**.

The package `terra` is now the package of reference for manipulating spatial data, spatial analysis and modeling in R. It is a very large topics and here we cover the basics of data manipulation.

Because of the many changes happening in the past few years related to spatial data analysis in R, this section of the course is still under developement. **The information below are largely extracted form Terra online tutorial available [here](https://rspatial.org/spatial/2-spatialdata.html).**


# Spatial data

Spatial phenomena can generally be thought of as either discrete objects with clear boundaries or as a continuous phenomena that can be observed everywhere, but that do not have natural boundaries. Discrete spatial objects may refer to a river, road, country, town, or a research site. Examples of continuous phenomena, or **spatial fields**, include elevation, temperature, and air quality.

Spatial objects are usually represented by vector data. Such data consists of a description of the **geometry** or **shape** of the objects, and normally also includes additional variables. For example, a vector data set may represent the borders of the countries of the world (geometry), and also store their names and the size of their population in 2015; or it may have the geometry of the roads in an area, as well as their type and names. These additional variables are often referred to as **attributes**. Continuous spatial data (fields) are usually represented with a raster data structure. We discuss these two data types in turn.

## Vector data

The main vector data types are points, lines and polygons. In all cases, the geometry of these data structures consists of sets of coordinate pairs (x, y). Points are the simplest case. Each point has one coordinate pair, and n associated variables. For example, a point might represent a place where a rat was trapped, and the attributes could include the date it was captured, the person who captured it, the species size and sex, and information about the habitat. It is also possible to combine several points into a multi-point structure, with a single attribute record. For example, all the coffee shops in a town could be considered as a single geometry.

The geometry of lines is a just a little bit more complex. First note that in this context, the term *line* refers to a set of one or more polylines (connected series of line segments). For example, in spatial analysis, a river and all its tributaries could be considered as a single *line* (but they could also also be several lines, perhaps one for each tributary river). Lines are represented as ordered sets of coordinates (nodes). The actual line segments can be computed (and drawn on a map) by connecting the points. Thus, the representation of a line is very similar to that of a multi-point structure. The main difference is that for a line the ordering of the points is important, because we need to know in which order the points should be connected.

A network (e.g. a road or river network), or spatial graph, is a special type of lines geometry where there is additional information about things like flow, connectivity, direction, and distance.

A polygon refers to a set of closed polylines. The geometry is very similar to that of lines, but to close a polygon the last coordinate pair coincides with the first pair. A complication with polygons is that they can have holes (that is a polygon entirely enclosed by another polygon, that serves to remove parts of the enclosing polygon (for example to show an island inside a lake. Also, valid polygons do not self-intersect (but it is OK for a line to self-cross). Again, multiple polygons can be considered as a single geometry. For example, Indonesia consists of many islands. Each island can be represented by a single polygon, but together then can be represent a single (multi-) polygon representing the entire country.

## Raster data

Raster data is commonly used to represent spatially continuous phenomena such as elevation. A raster divides the world into a grid of equally sized rectangles (referred to as cells or, in the context of satellite remote sensing, pixels) that all have one or more values (or missing values) for the variables of interest. A raster cell value should normally represent the average (or majority) value for the area it covers. However, in some cases the values are actually estimates for the center of the cell (in essence becoming a regular set of points with an attribute).

In contrast to vector data, in raster data the geometry is not explicitly stored as coordinates. It is implicitly set by knowing the spatial extent and the number or rows and columns in which the area is divided. From the extent and number of rows and columns, the size of the raster cells (spatial resolution) can be computed. While raster cells can be thought of as a set of regular polygons, it would be very inefficient to represent the data that way as coordinates for each cell would have to be stored explicitly. Doing so would also dramatically increase processing time.

Continuous surface data are sometimes stored as triangulated irregular networks (TINs); these are not discussed here.

## Simple representation of spatial data

The basic data types in R are numbers, characters, logical (TRUE or FALSE) and factor values. Values of a single type can be combined in vectors and matrices, and variables of multiple types can be combined into a data.frame. We can represent (only very) basic spatial data with these data types. Let’s say we have the location (represented by longitude and latitude) of ten weather stations (named A to J) and their annual precipitation.

In the example below we make a very simple map. Note that a map is special type of plot (like a scatter plot, barplot, etc.). A map is a plot of geospatial data that also has labels and other graphical objects such as a scale bar or legend. The spatial data itself should not be referred to as a map.

```{r,  eval=T}
name <- LETTERS[1:10]
longitude <- c(-116.7, -120.4, -116.7, -113.5, -115.5,
               -120.8, -119.5, -113.7, -113.7, -110.7)
latitude <- c(45.3, 42.6, 38.9, 42.1, 35.7, 38.9,
              36.2, 39, 41.6, 36.9)
stations <- cbind(longitude, latitude)
# Simulated rainfall data
set.seed(0)
precip <- round((runif(length(latitude))*10)^3)
```

A map of point locations is not that different from a basic x-y scatter plot. Below is a plot (a map in this case) that shows the location of the weather stations, and the size of the dots is proportional to the amount of precipitation. The point size is set with argument cex.

```{r,  eval=T}
psize <- 1 + precip/500
plot(stations, cex=psize, pch=20, col='red', main='Precipitation')
# add names to plot
text(stations, name, pos=4)
# add a legend
breaks <- c(100, 250, 500, 1000)
legend.psize <- 1+breaks/500
legend("topright", legend=breaks, pch=20, pt.cex=legend.psize, col='red', bg='gray')
```

Note that the data are represented by “longitude, latitude”, in that order, do not use “latitude, longitude” because on most maps latitude (North/South) is used for the vertical axis and longitude (East/West) for the horizontal axis. This is important to keep in mind, as it is a very common source of mistakes!


We can add multiple sets of points to the plot, and even draw lines and polygons:


```{r,  eval=T}
lon <- c(-116.8, -114.2, -112.9, -111.9, -114.2, -115.4, -117.7)
lat <- c(41.3, 42.9, 42.4, 39.8, 37.6, 38.3, 37.6)
x <- cbind(lon, lat)
plot(stations, main='Precipitation')
polygon(x, col='blue', border='light blue')
lines(stations, lwd=3, col='red')
points(x, cex=2, pch=20)
points(stations, cex=psize, pch=20, col='red', main='Precipitation')
```

The above illustrates how numeric vectors representing locations can be used to draw simple maps. It also shows how points can (and typically are) represented by pairs of numbers. A line and a polygon can be represented by a number of these points. Polygons need to “closed”, that is, the first point must coincide with the last point, but the `polygon` function took care of that for us.

There are cases where a simple approach like this may suffice and you may come across this in older R code or packages. Likewise, raster data could be represented by a matrix or higher-order array. Particularly when only dealing with point data such an approach may be practical. For example, a spatial data set representing points and attributes could be made by combining geometry and attributes in a single `data.frame`.

```{r,  eval=T}
wst <- data.frame(longitude, latitude, name, precip)
wst
```


However, `wst` is a data.frame and R does not automatically understand the special meaning of the first two columns, or to what coordinate reference system it refers (longitude/latitude, or perhaps UTM zone 17S, or ….?).

Moreover, it is non-trivial to do some basic spatial operations. For example, the blue polygon drawn on the map above might represent a state, and a next question might be which of the 10 stations fall within that polygon. And how about any other operation on spatial data, including reading from and writing data to files? To facilitate such operation a number of R packages have been developed that define new spatial data types that can be used for this type of specialized operations.

Recent packages in R that define such spatial data structures include `terra` and `sf`. These packages replace a set of older packages including `raster` and `sp`.

We mostly use the `terra` package in these materials. You can install the latest released version of terra from CRAN with `install.packages("terra")`.


# Reading and writing spatial data


Reading and writing spatial data is complicated by the fact that there are many different file formats. However, there are a few formats that are most common that we discuss here.

## Vector files

The shapefile is the most commonly used file format for vector data (if you are not familiar with this file format, an important thing to understand is that a shapefile is really a set of at least three (ideally four) files, with all the same name, but different extension. For shapefile x you must have, in the same directory, these three files: x.shp, x.shx, x.dbf, and ideally also x.prj.

It is easy to read and write such files. Here we use a shapefile that comes with the `terra` package.

### Reading

Let's first download some spatial data of Taiwan using the `geodata` package:

```{r,  eval=F}
library (geodata)
#TWN <- gadm(country="TWN", level=1, path=tempdir())
#TWN <- gadm(country="TWN", level=1, path="./data"
TWN <- vect('data/gadm/gadm41_TWN_1_pk.rds')
TWN
# check for ?gadm
```

Using a .shp file, we can use the `vect` function from the `terra` package to read the file. First:

```{r,  eval=T}
# example using .shp file
library(terra)
filename1 <- system.file("ex/lux.shp", package="terra")
basename(filename1)
```
> We use the system.file function to get the full path name of the file’s location. We need to do this as the location of this file depends on where the terra package is installed. You should not use the system.file function for your own files. It only serves for creating examples with data that ship with R. With your own files, just use the filename (and path if the file is not in your working directory).

Then:

```{r,  eval=T}
# example using .shp file
s1 <- vect(filename1)
s1
```

The `vect` function returns `SpatVector` objects. It is important to recognise the difference between this type of R object (`SpatVector`), and the file (“shapefile”) that was used to create it. Thus, you should never say “I have a shapefile in R”, say “I have a SpatVector of polygons in R”, (and in some cases you can add “created from a shapefile”). The shapefile is one of many file formats for vector data.

### Writing

You can write new files using the `writeVector` method. You need to add argument `overwrite=TRUE` if you want to overwrite an existing file.

```{r,  eval=T}
TWN <- vect('data/gadm/gadm41_TWN_1_pk.rds')
outfile1 <- "data/shp_TWN.shp"
writeVector(TWN, outfile1, overwrite=TRUE)
```

## Raster files

The terra package can read and write several raster file formats.

### Reading raster data


Get raster data of taiwan elevation using the `geodata` package:

```{r,  eval=T}
library(geodata)
ele <-elevation_30s("TWN", path=tempdir())
ele
```

Using a .tif file, we can use the `rast` function from the `terra` package to read the file. Firstusing example file from the package:

```{r,  eval=T}
f <- system.file("ex/logo.tif", package="terra")
basename(f)
```

Now we can do

```{r,  eval=T}
r <- rast(f)
r
```

Note that x is a SpatRaster of three layers (“bands”). We can subset it to get a single layer.

```{r,  eval=T}
r2 <- r[[2]]
r2
```

The same approach holds for other raster file formats, including GeoTiff, NetCDF, Imagine, and ESRI Grid formats.

### Writing raster data

Use `writeRaster` to write raster data. You must provide a SpatRaster and a filename. The file format will be guessed from the filename extension. If that does not work you can provide an argument like `format=GTiff`. Note the argument `overwrite=TRUE` and see `?writeRaster` for more arguments, such as `datatype=` to set the a specific datatype (e.g., integer).

```{r,  eval=T}
x <- writeRaster(ele, "data/ele.tif", overwrite=TRUE)
x
```

# Coordinate Reference Systems

A very important aspect of spatial data is the coordinate reference system (CRS) that is used. For example, a location of (140, 12) is not meaningful if you do know where the origin (0,0) is and if the x-coordinate is 140 meters, feet, nautical miles, kilometers, or perhaps degrees away from the x-origin.


## Coordinate Reference Systems (CRS)

### Angular coordinates

The earth has an irregular spheroid-like shape. The natural coordinate reference system for geographic data is longitude/latitude. This is an angular coordinate reference system. The latitude 
 (phi) of a point is the angle between the equatorial plane and the line that passes through a point and the center of the Earth. Longitude 
 (lambda) is the angle from a reference meridian (lines of constant longitude) to a meridian that passes through the point.

Obviously we cannot actually measure these angles. But we can estimate them. To do so, you need a model of the shape of the earth. Such a model is called a “datum”. The simplest datums are a spheroid (a sphere that is “flattened” at the poles and bulges at the equator). More complex datums allow for more variation in the earth’s shape. The most commonly used datum is called WGS84 (World Geodesic System 1984). This is very similar to NAD83 (The North American Datum of 1983). Other, local datums exist to more precisely record locations for a single country or region.

So the basic way to record a location is a coordinate pair in degrees and a reference datum. Sometimes people say that their coordinates are “in WGS84”. That does not tell us much; they typically mean to say that they are longitude/latitude relative to the WGS84 datum. Likewise longitude/latitude coordinates are sometimes referred to as “geographic” coordinates. That is rather odd, if planar coordinate reference systems (see below) are not geographic, what are they?

### Projections

A major question in spatial analysis and cartography is how to transform this three dimensional angular system to a two dimensional planar (sometimes called “Cartesian”) system. A planar system is easier to use for certain calculations and required to make maps (unless you have a 3-d printer). The different types of planar coordinate reference systems are referred to as “projections”. Examples are “Mercator”, “UTM”, “Robinson”, “Lambert”, “Sinusoidal” and “Albers”.

There is not one best projection. Some projections can be used for a map of the whole world; other projections are appropriate for small areas only. One of the most important characteristics of a map projection is whether it is “equal area” (the scale of the map is constant) or “conformal” (the shapes of the geographic features are as they are seen on a globe). No two dimensional map projection can be both conformal and equal-area (but they can be approximately both for smaller areas, e.g. UTM, or Lambert Equal Area for a larger area), and some are neither.

### Notation

A planar CRS is defined by a projection, datum, and a set of parameters. The parameters determine things like where the center of the map is. The number of parameters depends on the projection. It is therefore not trivial to document a projection used, and several systems exist. In R we used to depend on the PROJ.4 notation. PROJ.4 is the name of a software library that is commonly used for CRS transformation. You can find many more of these on [spatialreference.org](https://spatialreference.org/ref/epsg/4326/)

The PROJ.4 notation is no longer fully supported in the newer versions of the library (that was renamed to PR$\phi$J). It still works for CRSs with the WGS84 datum. For other cases you have to use a EPSG code (if available) or a Well-Known-Text notation.

Most commonly used CRSs have been assigned a “EPSG code” (EPSG stands for European Petroleum Survey Group). This is a unique ID that can be a simple way to identify a CRS. For example `EPSG:27561` is equivalent to `+proj=lcc +lat_1=49.5 +lat_0=49.5 +lon_0=0 +k_0=0.999877341 +x_0=6 +y_0=2 +a=6378249.2 +b=6356515 +towgs84=-168,-60,320,0,0,0,0 +pm=paris +units=m +no_defs`.

Now let’s look at an example with a spatial data set in R.



```{r,  eval=T}
s1
```

We can inspect the coordinate reference system like this.

```{r,  eval=T}
crs(s1)
```

## Assigning CRS

Sometimes we have data without a CRS. This can be because the file used was incomplete, or perhaps because we created the data ourselves with R code. In that case we can assign the CRS if we know what it should be. Here I first remove the CRS of `pp` and then I set it again.

```{r,  eval=T}
ss <- s1
crs(ss) <- ""
crs(ss)
crs(ss) <- "+proj=longlat +datum=WGS84"
crs(ss)
```

Note that you should not use this approach to change the CRS of a data set from what it is to what you want it to be. Assigning a CRS is like labeling something. You need to provide the label that corresponds to the item. Not to what you would like it to be. For example if you label a bicycle, you can write “bicycle”. Perhaps you would prefer a car, and you can label your bicycle as “car” but that would not do you any good. It is still a bicycle. You can try to transform your bicycle into a car. That would not be easy. Transforming spatial data is easier.

## Transforming vector data

We can transform these data to a new data set with another CRS using the `project` method.

Here we use the Robinson projection. First we need to find the correct notation.

```{r,  eval=T}
newcrs <- "+proj=robin +datum=WGS84"
```

Now use it: 

```{r,  eval=T}
rob <- terra::project(s1, newcrs)
rob
```

After the transformation, the units of the geometry are no longer in degrees, but in meters away from (longitude=0, latitude=0). The spatial extent of the data is also in these units.

We can backtransform to longitude/latitude:

```{r,  eval=T}
p2 <- terra::project(rob, "+proj=longlat +datum=WGS84")
```

## Transforming raster data

Vector data can be transformed from lon/lat coordinates to planar and back without loss of precision. This is not the case with raster data. A raster consists of rectangular cells of the same size (in terms of the units of the CRS; their actual size may vary). It is not possible to transform cell by cell. For each new cell, values need to be estimated based on the values in the overlapping old cells. If the values are categorical data, the “nearest neighbor” method is commonly used. Otherwise some sort of interpolation is employed (e.g. “bilinear”).

Because projection of rasters affects the cell values, in most cases you will want to avoid projecting raster data and rather project vector data. But here is how you can project raster data.

```{r,  eval=T}
r <- rast(xmin=-110, xmax=-90, ymin=40, ymax=60, ncols=40, nrows=40)
values(r) <- 1:ncell(r)
r
plot (r)
```

The simplest approach is to provide a new crs (the Robinson crs in this case):

```{r,  eval=T}
newcrs
pr1 <- terra::project(r, newcrs)
crs(pr1)
plot(pr1)
```

But that is not a good method. As you should want to assure that you project fits to exactly the raster parameters you need (so that it lines up with other raster data you are using).

To have this kind of control, provide an existing SpatRaster with the geometry you desire. That is generally the best way to project raster. By providing an existing SpatRaster, such that your newly projected data perfectly aligns with it. In this example we do not have an existing SpatRaster object, so we create from the result obtained above.

```{r,  eval=T}
x <- rast(pr1)
# Set the cell size
res(x) <- 200000
```

Now project, and note the change in the coordinates.

```{r,  eval=T}
pr3 <- terra::project(r, x)
pr3
plot(pr3)
```

For raster based analysis it is often important to use equal area projections, particularly when large areas are analyzed. This will assure that the grid cells are all of same size, and therefore comparable to each other, especially when count data are used.

# Vector data manipulation

This chapter illustrates some ways in which we can manipulate vector data. We start with an example SpatVector that we read from a shapefile.

```{r,  eval=T}
TWN <- vect('data/gadm/gadm41_TWN_1_pk.rds')
plot(TWN, "NAME_1")
```

We can plot these data in many ways. For example:

We can see this data set is incomplete for Taiwan. Let's get some data directly from Taiwan

```{r,  eval=F}
url <- 'https://data.moi.gov.tw/MoiOD/System/DownloadFile.aspx?DATA=72874C55-884D-4CEA-B7D6-F60B0BE85AB0'
path1 <- tempfile(fileext = ".zip")
if (file.exists(path1))  'file alredy exists' else download.file(url, path1, mode="wb")
zip::unzip(zipfile = path1,exdir = 'data')
```

Make `SpatialVector`:

```{r,  eval=T}
Taiwan <- "data/COUNTY_MOI_1130718.shp"
Taiwan <-vect(Taiwan)
```

Make the new plot: 

```{r,  eval=T}
plot(Taiwan, "COUNTYENG")
```


## Basics

### Geometry and attributes

To extract the attributes (data.frame) from a SpatVector, use:


```{r,  eval=T}
d <- as.data.frame(Taiwan)
# head(d) # not run for Chinese character
```
You can also extract the geometry as a a matrix (this is rarely needed).

```{r,  eval=T}
g <- geom(Taiwan) 
head(g)
```

Or as “well-known-text”.

```{r,  eval=T}
g <- geom(Taiwan, wkt=TRUE)
substr(g, 1, 50)
```

### Variables

You can extract a variable as you would do with a `data.frame`.

```{r,  eval=T}
Taiwan$COUNTYENG
```
To sub-set a SpatVector to one or more variables you can use the notation below. Note how this is different from the above example. Above a vector of values is returned. With the approach below you get a new SpatVector with only one variable.

```{r,  eval=T}
Taiwan[,"COUNTYENG"]
```

You can add a new variable to a SpatVector just as if it were a data.frame.

```{r,  eval=T}
set.seed(0)
Taiwan$lets <- sample(letters, nrow(Taiwan))
# Taiwan
```

Note that to get the number of geometries of SpatVector `Taiwan`, you can use `nrow(Taiwan)`, or `size(Taiwan)`. You can also do `perim(Taiwan)` to get the “length” of the spatial objects (zero for points, the length of the lines, or the perimeter of the polygons).

Assigning a new value to an existing variable.

```{r,  eval=T}
Taiwan$lets <- sample(LETTERS, nrow(Taiwan))
# head(Taiwan)
```

To get rid of a variable, set it to `NULL`.

```{r,  eval=T}
Taiwan$lets <- NULL
```

### Merge

You can assign an attributes table (data.frame) to a SpatVector with `values<-`. To add attributes to a SpatVector that already has attributes use `merge` (or `cbind` if you know the order of the records is the same).


```{r,  eval=T}
dfr <- data.frame(County=Taiwan$COUNTYENG, Value=round(runif(length(Taiwan), 100, 1000)))
dfr <- dfr[order(dfr$County), ]
pm <- merge(Taiwan, dfr, by.x="COUNTYENG",by.y="County")
# pm 
# head(pm)
```

Note the new variable `Value` added to `pm`

### Records

Selecting rows (records).

```{r,  eval=T}
i <- which(Taiwan$COUNTYENG == 'Taipei City')
g <- Taiwan[i,]
# g
```

It is also possible to interactively select and query records by clicking on a plotted dataset. That is difficult to show here. See `?sel` for interactively selecting geometries and `?click` to identify attributes by clicking on a plot (map).

## Append and aggregate

### Append

More example data. Object z consists of four polygons; z2 is one of these four polygons.

```{r,  eval=T}
z <- rast(Taiwan)
dim(z) <- c(2,2)
values(z) <- 1:4
names(z) <- 'Zone'
z <- as.polygons(z)
z
z1 <- z[1,]
z2 <- z[2,]
z3 <- z[3,]
z4 <- z[4,]
plot(Taiwan)
plot(z, add=TRUE, border='blue', lwd=5)
plot(z2, add=TRUE, border='red', lwd=2, col='red')
```

To append SpatVector objects of the same (vector) type you can use `rbind`:

```{r,  eval=T}
b <- rbind(Taiwan, z)
# head(b)
# tail(b)
```
Note how `rbind` allows you to append SpatVect objects with different attribute names, unlike the standard `rbind` for `data.frame`.


### Aggregate

It is common to aggregate (“dissolve”) polygons that have the same value for an attribute of interest. In this case, we want to highlight the North of Taiwan.


```{r,  eval=T}
Taiwan$region<-c(rep("Others",6), rep("North",3), rep("Others",2), "North", rep("Others",10))
pa <- aggregate(Taiwan, by='region')
za <- aggregate(z)
plot(za, col='light gray', border='light gray', lwd=5)
plot(pa, add=TRUE, col=rainbow(3), lwd=3, border='white')
```

It is also possible to aggregate polygons without dissolving the borders.

```{r,  eval=T}
Taiwan$region<-c(rep("Others",6), rep("North",3), rep("Others",2), "North", rep("Others",10))
pa <- aggregate(Taiwan, by='region',dissolve=FALSE)
za <- aggregate(z, dissolve = FALSE)
plot(za, col='light gray', border='dark gray', lwd=3)
plot(pa, add=TRUE, col=rainbow(3), lwd=2, border='white')
```

This is a structure that is similar to what you may get for an archipelago: multiple polygons represented as one entity (one row). Use `disagg` to split these up into their parts.

```{r,  eval=T}
zd <- disagg(pa)
zd
```

### Overlay

There are many different ways to “overlay” vector data. Here are some examples:

- Erase

Erase a part of a SpatVector

```{r,  eval=T}
e1 <- erase(Taiwan,z1 )
e2 <- erase(e1,z3 )
e3 <- erase(e2,z4 )
plot(e3)
```

- Intersect

Easier to complete with `intersect` SpatVectors

```{r,  eval=T}
i <- terra::intersect(Taiwan, z3)
plot(i)
```

You got Taiping Island. 

You can also `intersect` or `crop` with a SpatExtent (rectangle). The difference between `intersect` and `crop` is that with crop the geometry of the second argument is not added to the output.


```{r,  eval=T}
e <- ext(119, 123, 21, 26)
te <- crop(Taiwan, e)
plot(Taiwan)
plot(e, add=TRUE, lwd=3, col="red")
plot(te, col='light blue', add=TRUE)
plot(e, add=TRUE, lwd=3, border="blue")
```

- Union

Get the union of two SpatVectors.

```{r,  eval=T}
u <- terra::union(Taiwan, z)
u
```

Note that there are many more polygons now. One for each unique combination of polygons (and attributes in this case).

```{r,  eval=T}
set.seed(5)
plot(u, col=sample(rainbow(length(u))))
```

- Cover

`cover` is a combination of `intersect` and `union`. `intersect` returns new (intersected) geometries with the attributes of both input datasets. `union` appends the geometries and attributes of the input. `cover` returns the intersection and appends the other geometries and attributes of both datasets.

```{r,  eval=T}
cov <- cover(Taiwan, z[c(1,3),])
plot(cov)
```

- Difference

The symmetrical difference of two SpatVectors

```{r,  eval=T}
dif <- symdif(z,Taiwan)
plot(dif, col=rainbow(length(dif)))
```

### Spatial queries

We can query polygons with points (“point-in-polygon query”).

```{r,  eval=T}
pts <- matrix(c(117, 122, 117, 122, 15, 15, 23, 23), ncol=2)
spts <- vect(pts, crs=crs(Taiwan))
plot(z, col='light blue', lwd=2)
points(spts, col='light gray', pch=20, cex=6)
text(spts, 1:nrow(pts), col='red', font=2, cex=1.5)
lines(Taiwan, col='blue', lwd=2)
```

`extract` is used for queries between SpatVector and SpatRaster objects, and also for queries between SpatVectors.

```{r,  eval=T}
extract(spts, Taiwan)
```

# Raster data manipulation

`terra` has a large number of functions, not all of them are discussed here, and those that are discussed are mentioned only briefly. See the help files of the package for more information on individual functions and `help("terra-package")` for an index of functions by topic.

## Creating SpatRaster objects

A `SpatRaster` can easily be created from scratch using the function `rast`. The default settings will create a global raster data structure with a longitude/latitude coordinate reference system and 1 by 1 degree cells. You can change these settings by providing additional arguments such as `xmin`, `nrow`, `ncol`, and/or `crs`, to the function. You can also change these parameters after creating the object. If you set the projection, this is only to properly define it, not to change it. To transform a `SpatRaster` to another coordinate reference system (projection) you can use the `project` function.

Here is an example of creating and changing a SpatRaster object ‘r’ from scratch.


```{r,  eval=T}
library (terra)
x<-rast()
x
```

with some other parameters

```{r,  eval=T}
x <- rast(ncol=36, nrow=18, xmin=-1000, xmax=1000, ymin=-100, ymax=900)
```

These parameters can be changed. Resolution:

```{r,  eval=T}
res(x)
res(x) <- 100
res(x)
```

Change the number of columns (this affects the resolution).

```{r,  eval=T}
ncol(x)
ncol(x) <- 18
ncol(x)
res(x)
```

Set the coordinate reference system (CRS) (i.e., define the projection).

```{r,  eval=T}
crs(x) <- "+proj=utm +zone=48 +datum=WGS84"
x
```

The object `x` created in the examples above only consists of the raster *geometry*, that is, we have defined the number of rows and columns, and where the raster is located in geographic space, but there are no cell-values associated with it. Setting and accessing values is illustrated below.

First another example empty raster geometry.

```{r,  eval=T}
r <- rast(ncol=10, nrow=10)
ncell(r)
hasValues(r) # check if in-memory layers actually have cell values
```

Use the `values` function.

```{r,  eval=T}
values(r) <- 1:ncell(r)
```

Another example: 

```{r,  eval=T}
set.seed(0)
values(r) <- runif(ncell(r))
hasValues(r)
sources(r) # Get the data sources of a SpatRaster: Sources are either files (or similar resources) or "", meaning that they are in memory. 
values(r)[1:10]
plot(r, main='Raster with 100 cells')
```

In some cases, for example when you change the number of columns or rows, you will lose the values associated with the `SpatRaster` if there were any (or the link to a file if there was one). The same applies, in most cases, if you change the resolution directly (as this can affect the number of rows or columns). Values are not lost when changing the extent as this change adjusts the resolution, but does not change the number of rows or columns.

```{r,  eval=T}
hasValues(r)
res(r)
dim(r)
ext(r)
```

Now change the maximum x coordinate of the extent (bounding box) of the `SpatRaster`.

```{r,  eval=T}
xmax(r) <- 0
hasValues(r)
res(r)
dim(r)
```

And the number of columns (the values disappear)

```{r,  eval=T}
ncol(r) <- 6
hasValues(r)
res(r)
dim(r)
xmax(r)
```

While we can create a `SpatRaster` from scratch, it is more common to do so from a file. The `terra` package can use raster files in several formats, including GeoTiff, ESRI, ENVI, and ERDAS.

A notable feature of the `terra` package is that it can work with raster datasets that are stored on disk and are too large to be loaded into memory (RAM). The package can work with large files because the objects it creates from these files only contain information about the structure of the data, such as the number of rows and columns, the spatial extent, and the filename, but it does not attempt to read all the cell values in memory. In computations with these objects, data is processed in chunks. If no output filename is specified to a function, and the output raster is too large to keep in memory, the results are written to a temporary file.

Below we first we get the name of an example raster file that is installed with the `terra` package. Do not use this system.file construction for your own files. Just type the file name as you would do for any other file, but don’t forget to use forward slashes as path separators.

```{r,  eval=T}
filename <- system.file("ex/elev.tif", package="terra")
basename(filename)
```

That's teh file with the elevation of Luxembourg.

```{r,  eval=T}
r <- rast(filename)
sources(r)
hasValues(r)
plot(r, main="SpatRaster from file")
```

An example with GeoTiff of Taiwan Population density (2015) available [here](https://energydata.info/dataset/taiwan--population-density-2015/resource/ac982a4f-784b-4c9f-a124-8768556c89eb).


```{r,  eval=T}
tai.pop <- rast('./data/popmap15adj.tif')
par(mfrow=c(1,2))
# plot(tai.pop, main="Taiwan - Population Density (2015)")
# Need a log transformaton
plot(log(tai.pop+1), main="Taiwan - log-transformed Population Density (2015)")
```

We can also use our previous SpatRaster of elevation of Taiwan in a nicer map: 

```{r,  eval=T}
library(geodata)
library(ggplot2)
library(ggspatial)
ele <-elevation_30s("TWN", path=tempdir())
ggplot()+
  layer_spatial(ele)+
  scale_fill_continuous(na.value = 'transparent', name='Elevation (m)')+
  ggspatial::annotation_north_arrow(
    location = "tl", which_north = "true",
    style = ggspatial::north_arrow_nautical(fill = c("grey40", "white"), line_col = "grey20"))+
  ggspatial::annotation_scale () +
  theme_bw()
```

Multi-layer objects can be created in memory or from files.

Create three identical `SpatRaster` objects:


```{r,  eval=T}
r1 <- r2 <- r3 <- rast(nrow=10, ncol=10)
# Assign random cell values
values(r1) <- runif(ncell(r1))
values(r2) <- runif(ncell(r2))
values(r3) <- runif(ncell(r3))
```

Combine three `SpatRaster`:

```{r,  eval=T}
s <- c(r1, r2, r3)
s
nlyr(s)
```


You can also create a multilayer object from a file.

```{r,  eval=T}
filename <- system.file("ex/logo.tif", package="terra")
basename(filename)
b <- rast(filename)
b
nlyr(b)
```

Extract a single layer (the second one on this case)

```{r,  eval=T}
r <- b[[2]]
```

## Raster algebra (extra)

Many generic functions that allow for simple and elegant raster algebra have been implemented for Raster objects, including the normal algebraic operators such as `+`, `-`, `*`, `/`, logical operators such as `>`, `>=`, `<`, `==`, `!` and functions like `abs`, `round`, `ceiling`, `floor`, `trunc`, `sqrt`, `log`, `log10`, `exp`, `cos`, `sin`, `atan`, `tan`, `max`, `min`, `range`, `prod`, `sum`, `any`, `all`. In these functions you can mix raster objects with numbers, as long as the first argument is a raster object.

Create an empty `SpatRaster` and assign values to cells.

```{r,  eval=T}
r <- rast(ncol=10, nrow=10)
values(r) <- 1:ncell(r)
```

Now some raster algebra.

```{r,  eval=T}
s <- r + 10
s <- sqrt(s)
s <- s * r + 5
values(r) <- runif(ncell(r))
r <- round(r)
r <- r == 1
```

You can also use replacement functions.

```{r,  eval=T}
#Not yet implemented
s[r] <- -0.5
s[!r] <- 5
s[s == 5] <- 15
```


If you use multiple `SpatRaster` objects (in functions where this is relevant, such as range), these must have the same resolution and origin. The origin of a `Raster` object is the point closest to (0, 0) that you could get if you moved from a corner of a `SpatRaster` toward that point in steps of the x and y resolution. Normally these objects would also have the same extent, but if they do not, the returned object covers the spatial intersection of the objects used.

When you use multiple multi-layer objects with different numbers or layers, the ‘shorter’ objects are ‘recycled’. For example, if you multiply a 4-layer object (`a1`, `a2`, `a3`, `a4`) with a 2-layer object (`b1`, `b2`), the result is a four-layer object (`a1*b1`, `a2*b2`, `a3*b1`, `a3*b2`).

```{r,  eval=T}
r <- rast(ncol=5, nrow=5)
values(r) <- 1
s <- c(r, r+1)
q <- c(r, r+2, r+4, r+6)
x <- r + s + q
x
```

Summary functions (`min`, `max`, `mean`, `prod`, `sum`, `median`, `cv`, `range`, `any`, `all`) always return a `SpatRaster` object. Perhaps this is not obvious when using functions like `min`, `sum` or `mean`.

```{r,  eval=T}
a <- mean(r,s,10)
b <- sum(r,s)
st <- c(r, s, a, b)
sst <- sum(st)
sst
```


Use `global` if you want a single number summarizing the cell values of each layer.

```{r,  eval=T}
global(st, 'sum')
```

## ‘High-level’ functions (extra)

Several ‘high level’ functions have been implemented for `SpatRaster` objects. ‘High level’ functions refer to functions that you would normally find in a computer program that supports the analysis of raster data. Here we briefly discuss some of these functions. All these functions work for raster datasets that cannot be loaded into memory. See the help files for more detailed descriptions of each function.

The high-level functions have some arguments in common. The first argument is typically a `SpatRaster` ‘x’ or ‘object’. It is followed by one or more arguments specific to the function (either additional `SpatRaster` objects or other arguments), followed by `filename` and `...` arguments.

The default filename is an empty character `""`. If you do not specify a filename, the default action for the function is to return a `raster` object that only exists in memory. However, if the function deems that the `raster` object to be created would be too large to hold in memory, it is written to a temporary file instead.

The `...` argument allows for setting additional arguments that are relevant when writing values to a file: the file format, datatype (e.g. integer or real values), and a to indicate whether existing files should be overwritten.

### Modifying a SpatRaster object

There are several functions that deal with modifying the spatial extent of `SpatRaster` objects. The `crop` function lets you take a geographic subset of a larger `raster` object. You can crop a `SpatRaster` by providing an extent object or another spatial object from which an extent can be extracted (objects from classes deriving from `Raster` and from `Spatial` in the `sp` package). An easy way to get an extent object is to plot a `SpatRaster` and then use `drawExtent` to visually determine the new extent (bounding box) to provide to the crop function.

`trim` crops a `SpatRaster` by removing the outer rows and columns that only contain `NA` values. In contrast, `extend` adds new rows and/or columns with `NA` values. The purpose of this could be to create a new `SpatRaster` with the same Extent of another, larger, `SpatRaster` such that they can be used together in other functions.

The `merge` function lets you merge 2 or more SpatRaster objects into a single new object. The input objects must have the same resolution and origin (such that their cells neatly fit into a single larger raster). If this is not the case you can first adjust one of the SpatRaster objects with `aggregate`/`disagg` or `resample`.

`aggregate` and `disagg` allow for changing the resolution (cell size) of a SpatRaster object. In the case of aggregate, you need to specify a function determining what to do with the grouped cell values mean. It is possible to specify different (dis)aggregation factors in the x and y direction. `aggregate` and `disagg` are the best functions when adjusting cells size only, with an integer step (e.g. each side 2 times smaller or larger), but in some cases that is not possible.

For example, you may need nearly the same cell size, while shifting the cell centers. In those cases, the `resample` function can be used. It can do either nearest neighbor assignments (for categorical data) or bilinear interpolation (for numerical data). Simple linear shifts of a Raster object can be accomplished with the `shift` function or with the `extent` function.

With the `warp` function you can transform values of `SpatRaster` object to a new object with a different coordinate reference system.

Here are some simple examples.

Aggregate and disaggregate.

```{r,  eval=T}
r <- rast()
values(r) <- 1:ncell(r)
ra <- aggregate(r, 20)
rd <- disagg(ra, 20)
```

Crop and merge example.

```{r,  eval=T}
r1 <- crop(r, ext(-50,0,0,30))
r2 <- crop(r, ext(-10,50,-20, 10))
m <- merge(r1, r2, filename="test.tif", overwrite=TRUE)
plot(m)
```

`flip` lets you flip the data (reverse order) in horizontal or vertical direction – typically to correct for a ‘communication problem’ between different R packages or a misinterpreted file. `rotate` lets you rotate longitude/latitude rasters that have longitudes from 0 to 360 degrees (often used by climatologists) to the standard -180 to 180 degrees system. With `t` you can rotate a `SpatRaster` object 90 degrees.


### Overlay

`app` (short for “apply”) allows you to do a computation for a single `SpatRaster` object by providing a function, e.g. sum.

The `lapp` (layer-apply) function can be used as an alternative to the raster algebra discussed above.


### Classify

You can use `classify` to replace ranges of values with single values, or to substitute (replace) single values with other values.

```{r,  eval=T}
r <- rast(ncol=3, nrow=2)
values(r) <- 1:ncell(r)
values(r)
```

Set all values above 4 to `NA`

```{r,  eval=T}
s <- app(r, fun=function(x){ x[x < 4] <- NA; return(x)} )
as.matrix(s)
```

Divide the first raster with two times the square root of the second raster and add five.

```{r,  eval=T}
rs <- c(r, s)
w <- lapp(rs, fun=function(x, y){ x / (2 * sqrt(y)) + 5 } )
as.matrix(w)
```

Remove from r all values that are NA in w.

```{r,  eval=T}
u <- mask(r, w)
as.matrix(u)
```

Identify the cell values in `u` that are the same as in `s`.

```{r,  eval=T}
v <- u==s
as.matrix(v)
```

Replace `NA` values in w with values of `r`.

```{r,  eval=T}
cvr <- cover(w, r)
as.matrix(w)
```

Change value between 0 and 2 to 1, etc.

```{r,  eval=T}
x <- classify(w, rbind(c(0,2,1),  c(2,5,2), c(4,10,3)))
as.matrix(x)
```

Substitute 2 with 40 and 3 with 50.

```{r,  eval=T}
y <- classify(x, cbind(id=c(2,3), v=c(40,50)))
as.matrix(y)
```

### Focal methods


The `focal` methods computate new values based on the values in a neighborhood of cells around a focal cell, and putting the result in the focal cell of the output SpatRaster. The neighborhood is a user-defined matrix of weights and could approximate any shape by giving some cells zero weight. It is possible to only computes new values for cells that are `NA` in the input SpatRaster.


### Distance

There are a number of distance related functions. For example, you can compute the shortest distance to cells that are not `NA`, the shortest distance to any point in a set of points, or the distance when following grid cells that can be traversed (e.g. excluding water bodies). `direction` computes the direction toward (or from) the nearest cell that is not `NA`. `adjacency` determines which cells are adjacent to other cells. See the `gdistance` package for more advanced distance calculations (cost distance, resistance distance).

### Spatial configuration

`patches` identifies groups of cells that are connected. `boundaries` identifies edges, that is, transitions between cell values. `zonal` computes the size of each grid cell (for unprojected rasters), this may be useful to, e.g. compute the area covered by a certain class on a longitude/latitude raster.

```{r,  eval=T}
r <- rast(nrow=45, ncol=90)
values(r) <- round(runif(ncell(r))*3)
a <- cellSize(r)
zonal(a, r, "sum")
```

### Predictions

The `terra` package has two functions to make model predictions to (potentially very large) rasters. predict takes a multilayer raster and a fitted model as arguments. Fitted models can be of various classes, including glm, gam, and RandomForest. The function `interpolate` is similar but is for models that use coordinates as predictor variables, for example in Kriging and spline interpolation.

### Vector to raster conversion

The `terra` package supports point, line, and polygon to raster conversion with the `rasterize` function. For vector type data (points, lines, polygons), `SpatVector` objects are used; but points can also be represented by a two-column matrix (x and y).

Point to raster conversion is often done with the purpose to analyze the point data. For example to count the number of distinct species (represented by point observations) that occur in each raster cell. `rasterize` takes a `SpatRaster` object to set the spatial extent and resolution, and a function to determine how to summarize the points (or an attribute of each point) by cell.

Polygon to raster conversion is typically done to create a `SpatRaster` that can act as a mask, i.e. to set to `NA` a set of cells of a `SpatRaster` object, or to summarize values on a raster by zone. For example a country polygon is transferred to a raster that is then used to set all the cells outside that country to `NA`; whereas polygons representing administrative regions such as states can be transferred to a raster to summarize raster values by region.

It is also possible to convert the values of a `SpatRaster` to points or polygons, using `as.points` and `as.polygons`. Both functions only return values for cells that are not NA.

## Summarizing functions (extra)

When used with a `SpatRaster` object as first argument, normal summary statistics functions such as `min`, `max` and `mean` return a `SpatRaster`. You can use `global` if, instead, you want to obtain a summary for all cells of a single `SpatRaster` object. You can use `freq` to make a frequency table, or to count the number of cells with a specified value. Use `zonal` to summarize a SpatRaster object using zones (areas with the same integer number) defined in a `SpatRaster` and `crosstab` to cross-tabulate two `SpatRaster` objects.

```{r,  eval=T}
r <- rast(ncol=36, nrow=18)
values(r) <- runif(ncell(r))
global(r, mean)
```


Zonal stats, below `r` has the cells we want to summarize, `s` defines the zones, and the last argument is the function to summarize the values of `r` for each zone in `s`.

```{r,  eval=T}
s <- r
values(s) <- round(runif(ncell(r)) * 5)
zonal(r, s, 'mean')
```

Count cells

```{r,  eval=T}
freq(s)
freq(s, value=3)
```

Cross-tabulate

```{r,  eval=T}
ctb <- crosstab(c(r*3, s))
head(ctb)
```

## Helper functions

The cell number is an important concept in the terra package. Raster data can be thought of as a matrix, but in a `SpatRaster` it is more commonly treated as a vector. Cells are numbered from the upper left cell to the upper right cell and then continuing on the left side of the next row, and so on until the last cell at the lower right side of the raster. There are several helper functions to determine the column or row number from a cell and vice versa, and to determine the cell number for x, y coordinates and vice versa.


```{r,  eval=T}
r <- rast(ncol=36, nrow=18)
ncol(r)
nrow(r)
ncell(r)
rowFromCell(r, 100)
colFromCell(r, 100)
cellFromRowCol(r,5,5)
xyFromCell(r, 100)
cellFromXY(r, cbind(0,0))
colFromX(r, 0)
rowFromY(r, 0)
```

## Accessing cell values

Cell values can be accessed with several methods. Use `values` to get all values or a subset such as a single row or a block (rectangle) of cell values.


```{r,  eval=T}
r <- rast(system.file("ex/elev.tif", package="terra"))
v <- values(r)
v[3075:3080, ]
values(r, row=33, nrow=1, col=35, ncol=6)
```

You can also read values using cell numbers or coordinates (xy) using the `extract` method.

```{r,  eval=T}
cells <- cellFromRowCol(r, 33, 35:40)
cells
r[cells]
xy <- xyFromCell(r, cells)
xy
extract(r, xy)
```

You can also extract values using `SpatVector` objects. The default approach for extracting raster values with polygons is that a polygon has to cover the center of a cell, for the cell to be included. However, you can use argument `weights=TRUE` in which case you get, apart from the cell values, the percentage of each cell that is covered by the polygon, so that you can apply, e.g., a “50% area covered” threshold, or compute an area-weighted average.

In the case of lines, any cell that is crossed by a line is included. For lines and points, a cell that is only ‘touched’ is included when it is below or to the right (or both) of the line segment/point (except for the bottom row and right-most column).

In addition, you can use standard R indexing to access values, or to replace values (assign new values to cells) in a `SpatRaster` object. If you replace a value in a `SpatRaster` object based on a file, the connection to that file is lost (because it now is different from that file). Setting raster values for very large files will be very slow with this approach as each time a new (temporary) file, with all the values, is written to disk. If you want to overwrite values in an existing file, you can use `update` (with caution!)

```{r,  eval=T}
r[cells]
r[1:4]
sources(r)
r[2:5] <- 10
r[1:4]
sources(r)
```


Note that in the above examples values are retrieved using cell numbers. That is, a raster is represented as a (one-dimensional) vector. Values can also be inspected using a (two-dimensional) matrix notation. As for R matrices, the first index represents the row number, the second the column number.


```{r,  eval=T}
r[1:3]
r[1,1:3]
r[1, 1:5]
r[1:5, 2]
r[1:3,1:3]
# get a vector instead of a a matrix
r[1:3, 1:3, drop=TRUE]
# or a raster like matrix
as.matrix(r, wide=TRUE)[1:3, 1:4]
```

Accessing values through this type of indexing should be avoided inside functions as it is less efficient than accessing values via functions like `getValues`.

## Coercion to other classes

You can convert `SpatRaster` objects to `Raster*` objects defined in the raster package.

```{r,  eval=T}
r <- rast(ncol=36, nrow=18)
values(r) <- runif(ncell(r))
library(raster)
## Loading required package: sp
x <- raster(r)
```

# Maps


You can make a map with `plot(x)`, were `x` is a ``SpatRaster or a `SpatVector`. You can add additional spatial data or text with functions such as `points`, `lines`, `text`. `ggspatial` is specifically developed to handle spatial data using `ggplot2`

In theory, you can zoom in using `zoom(x)` and clicking on the map twice (to indicate where to zoom to). Or use `sel(x)` to save a spatial subset to a new object. With `click(x)` it is possible to interactively query a SpatRaster by clicking once or several times on a map plot.


## SpatVector

If you plot a SpatVector without further arguments, you get black points, lines or polygons, and no legend.

```{r,  eval=T}
plot(TWN)
```

Colors can simply be added like this:

```{r,  eval=T}
n <- nrow(TWN)
plot(TWN, col=rainbow(n))
```

But if you want colors it is probably easiest to use an attribute.

```{r,  eval=T}
plot(TWN, "NAME_1", col=rainbow(25))
```

You can request maps for multiple variables:

```{r,  eval=T}
plot(TWN, c("NAME_1", ""), col=rainbow(25))
```
Below we also make two maps, but do it “by hand”. We adjust the spacing, and put the legends inside the map area, and use non-rotated text for the vertical axis.


```{r,  eval=T}
par(mfrow=c(1,2))
m <- c(3.1, 3.1, 2.1, 2.1)
plot(TWN, "", mar=m, pax=list(las=1))
plot(TWN, "NAME_1", col=rainbow(25), mar=m, plg=list(x="bottomleft", cex=.75), pax=list(las=1))
```
More costumization. Choose the axes to draw, at a label and a box to the legend.

```{r,  eval=T}

par(mfrow=c(1,2))
m <- c(3.1, 3.1, 1.1, 1.1)
plot(TWN, "", mar=m, main="", axes=FALSE)
axis(1, at=c(5,7)); axis(1)
axis(2, at=c(49,51)); axis(2, las=1)
plot(TWN, "NAME_1", col=rainbow(25), mar=m, plg=list(x="bottomleft", cex=.75, title="County", bty = "o"), main="", axes=FALSE)
axis(1, at=c(5, 7)); axis(1)
```



We can combine multiple SpatVectors using `lines` and `points` to draw on top of what we plotted first.

```{r,  eval=T}
d <- aggregate(TWN, "NAME_1")
plot(TWN, col="light blue", lty=2, lwd=2)
lines(d, lwd=5)
lines(d, col="white", lwd=1)
text(TWN, "NAME_1", cex=.8, halo=TRUE)
```


The `rasterVis` package provides a lot of very nice plotting options as well.

## SpatVector


The default display of a single layer SpatRaster depends on the data type, but there will always be a legend.

```{r,  eval=T}
plot(ele)
```

After plotting a `SpatRaster` you can add vector type spatial data (points, lines, polygons). You can do this with functions `points`, `lines`, `polys` or `plot` (object, add=TRUE).

```{r,  eval=T}
plot(ele)
lines(TWN, lwd=2)
set.seed(12)
xy <- spatSample(ele, 20, "random", na.rm=TRUE, xy=TRUE)
points(xy, pch=20, col="red", cex=2)
```

Or use a different legend type:

```{r,  eval=T}
m <- c(3.1, 3.1, 1.1, 1.1)
plot(ele, type="interval", plg=list(x="bottomleft"), mar=m)
```
If there are only a few values, the default is to show “classes”

```{r,  eval=T}
rr <- round(ele/600)
plot(rr, plg=list(x="topleft"), mar=m)
```


If the raster is categorical you get the category labels in the legend.

Make a categorical (factor) raster

```{r,  eval=T}
x <- classify(ele, c(-12, 500, 1500, 4000))
levels(x) <- data.frame(id=0:2, elevation=c("low", "intermediate", "high"))
# is.factor(x)
plot(x, col=c("green", "blue", "light gray"))
```
When plot is used with a multi-layer object, all layers are plotted (up to 16), unless the layers desired are indicated with an additional argument.

```{r,  eval=T}
library(terra)
b <- rast(system.file("ex/logo.tif", package="terra"))
plot(b)
```

In this case, it makes sense to combine the three layers into a single image, by assigning individual layers to one of the three color channels (red, green and blue):

```{r,  eval=T}
plotRGB(b, r=1, g=2, b=3)
```

You can also use a number of other plotting functions with SpatRasters, including `hist`, `persp`, `contour`, and `density`. See the help files for more info.

The `rasterVi`s and `tmap` packages provides a lot of very nice mapping options as well.

## Basemaps

You can get many different base-maps with the `maptiles` package. Reading the data again.

```{r,  eval=T}
library(maptiles)
bg <- get_tiles(ext(Taiwan))
plotRGB(bg)
lines(TWN, col="blue", lwd=3)
```

## Interactive maps

You can use the `leaflet` package to make interactive maps.

```{r,  eval=T}
#remotes::install_github("rstudio/leaflet")
library(leaflet)
m <- plet(Taiwan, alpha=0.5, fill=0.5)
m
```

